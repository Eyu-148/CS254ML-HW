{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Eyu_Chen_Assignment3 .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eyu-148/CS254ML-HW/blob/main/Eyu_Chen_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHjmkdJFUJWq"
      },
      "source": [
        "# Assignment 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2IyCpeDUJWt"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from past.builtins import xrange\n",
        "from scipy.special import expit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2xU9XeCUJWu"
      },
      "source": [
        "# Assignment 3 - Part 1(Logistic regression without regularization)\n",
        "\n",
        "In this exercise, you will implement logistic regression and apply it to the dataset Iris.csv\n",
        "\n",
        "In this dataset there are two continuous variables named \"PetalLengthCm\" and \"PetalWidthCm\". Yhe type of flower associated with these features is assigned in the \"species\" column. Setosa is labeled as 0 and Versicolor is labeled as 1. Your task will be to classify between these two types of flowers.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "uvbvLqLSUJWv"
      },
      "source": [
        "### Part 1, Q1 -  [20 pts]\n",
        "\n",
        "1. [10 points] Load the data and split it into X(feature vectors) and Y(target/output vectors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbKvM2bvUJWv",
        "outputId": "df8f0939-0825-451f-f2fe-d68065ca5316"
      },
      "source": [
        "# Load iris dataset\n",
        "# Note: This dataset must be contained in a \"data\" folder\n",
        "path = 'https://raw.githubusercontent.com/Eyu-148/CS254ML-HW/main/Iris.csv'\n",
        "data = pd.read_csv(path)\n",
        "data.head()\n",
        "print(data)\n",
        "\n",
        "data['ones'] = np.ones(data.shape[0])\n",
        "\n",
        "# Split data into X and Y\n",
        "x = data[[\"PetalLengthCm\", \"PetalWidthCm\", \"ones\"]].values\n",
        "y = data[\"Species\"].values.reshape(len(data),1)\n",
        "print(np.shape(x), np.shape(y), np.shape(x.T))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Id  PetalLengthCm  PetalWidthCm  Species\n",
            "0     1            1.4           0.2        0\n",
            "1     2            1.4           0.2        0\n",
            "2     3            1.3           0.2        0\n",
            "3     4            1.5           0.2        0\n",
            "4     5            1.4           0.2        0\n",
            "..  ...            ...           ...      ...\n",
            "95   96            4.2           1.2        1\n",
            "96   97            4.2           1.3        1\n",
            "97   98            4.3           1.3        1\n",
            "98   99            3.0           1.1        1\n",
            "99  100            4.1           1.3        1\n",
            "\n",
            "[100 rows x 4 columns]\n",
            "(100, 3) (100, 1) (3, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-f2rtS7UJWw"
      },
      "source": [
        "2. [10 points] Visualize the data. \n",
        "For visualizing,PetalLengthCm will be in the X-axis and PetalWidthCm will be on the Y-axis. Additionally, assign '+' for Setosa points and 'o' for versicolor points.for Setosa, and circle for versicolor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSxqSXORUJWx",
        "outputId": "45569cc2-f8b4-426d-c41a-5fd8adfd2de0"
      },
      "source": [
        "# Write your code here\n",
        "# Reading through by Id, which should be i\n",
        "# for id in data.values[:, 0]:\n",
        "for (a, b, s) in zip(data.values[:,1], data.values[:,2], data.values[:,3]):\n",
        "    if s == 0:\n",
        "        plt.scatter(a, b, color='b', marker=\"+\")\n",
        "    if s == 1:\n",
        "        plt.scatter(a, b, color='b', marker=\"o\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpguSSERUJWy"
      },
      "source": [
        "### Part 1, Q2 -  [10 pts]\n",
        "\n",
        "Before you start with the implementation of the cost function and gradient descent algorithm for logistic Regression, at first implement the function \"sigmoid\"  that can be called by the rest of your program. Test it when you are finished. Try testing a few values by calling sigmoid(x). For large positive values of x, the sigmoid should be close to 1, while for large negative values, the sigmoid should be close to 0. Evaluating sigmoid(0) should give you exactly 0.5.\n",
        "The equation for sigma is \n",
        "![](https://github.com/Eyu-148/CS254ML-HW/blob/main/images/H1.png?raw=1)\n",
        "Here \n",
        "\n",
        "![](https://github.com/Eyu-148/CS254ML-HW/blob/main/images/H2.png?raw=1)\n",
        "\n",
        "The dimension of Z should be (100,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O5GTdZFUJWy"
      },
      "source": [
        "def sigmoid(Z):\n",
        "    return 1 / (1+np.exp(-Z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdytPwjXUJWz",
        "outputId": "aeada3f9-8f20-41dd-a4fa-9260a0c9637e"
      },
      "source": [
        "# The following lines are for few test case check. You sigmoid should be fine if you are passing this test cases.\n",
        "assert sigmoid(0) == 0.5, \"The sigmoid function is wrong.\"\n",
        "assert 1.1 > sigmoid(100)  > 0.9999, \"The sigmoid function is wrong.\"\n",
        "assert -0.1 < sigmoid(-100) < 0.0001, \"The sigmoid function is wrong.\"\n",
        "\n",
        "# visual inspection\n",
        "# This below line will help you to test your sigmoid function for diiferrent values between -1 and 1. \n",
        "list(\"x: %6.3f sigx: %6.3f\"% (x, sigx) for (sigx, x) in  zip(sigmoid(np.linspace(-1,1,11)), np.linspace(-1,1,11)))\n",
        "# plt.plot(np.linspace(-6, 6, 101), sigmoid(np.linspace(-6, 6, 101)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['x: -1.000 sigx:  0.269',\n",
              " 'x: -0.800 sigx:  0.310',\n",
              " 'x: -0.600 sigx:  0.354',\n",
              " 'x: -0.400 sigx:  0.401',\n",
              " 'x: -0.200 sigx:  0.450',\n",
              " 'x:  0.000 sigx:  0.500',\n",
              " 'x:  0.200 sigx:  0.550',\n",
              " 'x:  0.400 sigx:  0.599',\n",
              " 'x:  0.600 sigx:  0.646',\n",
              " 'x:  0.800 sigx:  0.690',\n",
              " 'x:  1.000 sigx:  0.731']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov6BfBJAUJW0"
      },
      "source": [
        "### Part 1, Q3 -  [20 pts]\n",
        "\n",
        "\n",
        "\n",
        "1.  [20 points] Implement cost function (calcLogRegressionCost) as detailed in the cell below.\n",
        "\n",
        "The vectorized equation for the cost function is given below for your convenient.  \n",
        "\n",
        "![](https://github.com/Eyu-148/CS254ML-HW/blob/main/images/J1.png?raw=1)\n",
        "\n",
        "\n",
        "\n",
        "Hint: Once you are done,  call your \"calcLogRegressionCost\" using the initial parameters of θ. You should see that the cost is about 0.693.\n",
        "\n",
        "Note: no need to add the regularization term. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35R5a4QFUJW0"
      },
      "source": [
        "# You may change the number of parameters according to your wish for\n",
        "# all the funtions depending on your implementation.\n",
        "\n",
        "def calcLogRegressionCost(x, y, theta):\n",
        "    # x : the feature vector\n",
        "    # y : target vector / output vector\n",
        "    # theta : weight vector \n",
        "    \n",
        "    m = x.shape[0]\n",
        "    error = y.T.dot(np.log(sigmoid(x.dot(theta)))) + (1-y).T.dot(np.log(1-sigmoid(x.dot(theta))))\n",
        "    #cost = (np.dot(y.T, np.log(sigmoid(np.dot(x, theta)))) +  np.dot((1-y).T, np.log(1-sigmoid(np.dot(x, theta)))))/ -m\n",
        "    cost = error / -m\n",
        "    return cost\n",
        "\n",
        "def logRegressionGradientDescent(x, y, thetaInit, eta, epochs):\n",
        "    # x : feature vector\n",
        "    # Y : target vector/ output vector\n",
        "    # theta : weight vector \n",
        "    # eta : learning rate\n",
        "    # epochs : gradient descent steps taken\n",
        "    \n",
        "    m, d = x.shape\n",
        "    theta = thetaInit.copy()\n",
        "\n",
        "    losses = [calcLogRegressionCost(x, y, theta)]\n",
        "    for i in range(epochs):\n",
        "        gradient = 2 * (x.T.dot(sigmoid(x.dot(theta)) - y)) / m\n",
        "        theta -= eta * gradient\n",
        "        losses.append(calcLogRegressionCost(x, y, theta))\n",
        "\n",
        "    return theta, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHbW4pE1UJW1",
        "outputId": "d9abefcf-355e-4213-8e7c-026ac3e6572d"
      },
      "source": [
        "# This part is for testing your algorithms\n",
        "theta = np.zeros((x.shape[1], 1))\n",
        "print(calcLogRegressionCost(x, y, theta))\n",
        "# Desired output: 0.693..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.69314718]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5WXx-3BUJW1"
      },
      "source": [
        "### Part 1, Q4 -  [20 pts]\n",
        "\n",
        "As you have the gradient decent algorithm implemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGtBJgY6UJW1"
      },
      "source": [
        "1. [10 Points] Run the gradient descent algorithm to fit your parameters theta to the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEA65JlqUJW1",
        "outputId": "5eafc1bc-f237-4158-fda2-3a990e2a5e2e"
      },
      "source": [
        "eta = 0.1 \n",
        "epochs = 5000\n",
        "thetaInit = np.zeros((x.shape[1], 1))\n",
        "theta, cost = logRegressionGradientDescent(x, y, thetaInit, eta, epochs)\n",
        "print(calcLogRegressionCost(x, y, thetaInit))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.69314718]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ElVZ6zUJW2"
      },
      "source": [
        "2. [4 Points] Report optimal final θ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtIi635kUJW2",
        "outputId": "dcab7599-6eee-4cef-fd1b-32934d3684b9"
      },
      "source": [
        "# Write your code here\n",
        "print(\"Optimal theta:\\n\", theta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal theta:\n",
            " [[  2.80475893]\n",
            " [  4.23880022]\n",
            " [-10.18403071]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUmp2puEUJW2"
      },
      "source": [
        "\n",
        "3. [6 Points] Plot the cost vs the number of epochs. what is the best learning rate you chose and why ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR2muxtQUJW3",
        "outputId": "193075c2-3ee8-44fc-e3e4-1cd8b4dfe7ad"
      },
      "source": [
        "# Write your code here\n",
        "for (e, c) in zip(range(epochs), cost):\n",
        "    plt.scatter(e,c, color='b')\n",
        "    plt.plot(e, c, \"r\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE3hjgezUJW3"
      },
      "source": [
        "### Part 1, Q5 -  [30 pts]\n",
        "At this point, you have the optimal theta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgzxTEMAUJW3"
      },
      "source": [
        "1. [8 Points] Implement the predict_proba function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mF6ipo_UJW3"
      },
      "source": [
        "def predict_proba(x, theta):\n",
        "    # you need to know the probability of a certain test sample falling in a certain class.\n",
        "    # For this you need a function which will give you the probability.\n",
        "    # This function should return a probability\n",
        "    \n",
        "    # Start your code from here\n",
        "    prob = sigmoid(x.dot(theta))\n",
        "    return prob[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8lirIJFUJW3"
      },
      "source": [
        "2. [6 Points] Suppose that the petal length is 2.0 and petal width is 0.3. Using the predict_proba function, find the probability of this sample being a Setosa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbHc6K5IUJW4",
        "outputId": "dca39723-a79a-4447-d9b7-a09be52c5220"
      },
      "source": [
        "# Write your code here\n",
        "dataInit = np.array([2.0, 0.3, 1.0])\n",
        "prob = predict_proba(dataInit, theta)\n",
        "\n",
        "print(\"Probability to be a setosa:\", 1-prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probability to be a setosa: 0.9645272328756719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKw3a03_UJW4"
      },
      "source": [
        "3. [16 Points] Plot the decision boundary with respect to the data. The plot should include PetalLengthCm in the X-axis and PetalWidthCm in the Y-axis. Additionally, assign '+' for Setosa points and 'o' for versicolor points. The decision boundary should separate the classes using the optimal theta found in Part 1 Q3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsveqk4qUJW4"
      },
      "source": [
        "# write you plotting code here ...\n",
        "# Note: this function may need parameters\n",
        "def plotData():\n",
        "    for (a, b, s) in zip(data.values[:,1], data.values[:,2], data.values[:,3]):\n",
        "        if s == 0:\n",
        "            plt.scatter(a, b, color='b', marker=\"+\")\n",
        "        if s == 1:\n",
        "            plt.scatter(a, b, color='b', marker=\"o\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc-1vxdjUJW4"
      },
      "source": [
        "def plotDecisionBoundary(x, theta):\n",
        "    # x : the feature vector\n",
        "    # theta : weight vector \n",
        "    \n",
        "    # find min,max x values and solve for y = 0 at those positions\n",
        "    boundary_xs = np.array([np.min(x[:,1]), np.max(x[:,1])])\n",
        "    boundary_ys = -1 * (-.5 + theta[0] + theta[1]*boundary_xs) / theta[2]\n",
        "    \n",
        "    # plot points\n",
        "    plt.plot(boundary_xs, boundary_ys, 'b-', label='Decision Boundary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fc0NzesUJW4",
        "outputId": "00496111-0a1c-4ee2-8343-f9561b35a725"
      },
      "source": [
        "plotData() # Note: this function may need parameters\n",
        "#print(x)\n",
        "plotDecisionBoundary(x, theta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-B94bvUUJW5"
      },
      "source": [
        "# Assignment 3 - Part 2 (Enhanced Logistic regression)\n",
        "# Required for Graduate Students, extra credit for Undergraduates\n",
        "\n",
        "Import and examine the dataset ex2data2.txt. There are two continuous independent variables in the data - “Test 1” and “Test 2”. Our target variable is binary and labeled 0(did not passed the test) or 1(passed the test).\n",
        "\n",
        "In this part of the Assignment, you will build a logistic regression model to predict whether a sample passed the test or not (a model that estimates the probability of being passed or not based on test 1 and test 2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeCehLOFUJW5"
      },
      "source": [
        "### Part 2, Q1 -  [15 pts]\n",
        "\n",
        "1. [5 Points]  Load the data and visualize it. (You can follow the steps from part1, Q1)\n",
        "\n",
        "For visualizing, test 1 will be in the X-axis, test 2 will be on the Y-axis. Assign '+' for Setosa points and 'o' for versicolor points.for Setosa, and circle for versicolor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7jHgxTGUJW5"
      },
      "source": [
        "path = os.getcwd() + '/data/ex2data2.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkpgJz3pUJW5"
      },
      "source": [
        "# write you plotting code here ...\n",
        "# Note: this function may need parameters\n",
        "def plotData():\n",
        "\n",
        "plotData()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QNex_k5UJW6"
      },
      "source": [
        "\n",
        "Before going further, you will be implementing Ridge regularized gradient descent with its corresponding regularized cost function, which will be needed at the end of the assignment.\n",
        "    \n",
        "\n",
        "2. [5 Points] Implement Ridge Regularized Logistic Regression cost function named calcLogRegressionCostR following the given equation.\n",
        "The equation is ![](https://github.com/Eyu-148/CS254ML-HW/blob/main/images/G2.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TccNcJJWUJW6"
      },
      "source": [
        "def calcLogRegressionCostR(x, y, theta, alpha=0):\n",
        "    # x : feature vector\n",
        "    # y : target vector/ output vector\n",
        "    # theta : weight vector\n",
        "    # alpha : regularization parameter\n",
        "\n",
        "    # add code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gskyplHSUJW6"
      },
      "source": [
        "3. [5 Points] Implement logRegressionGradientDescentR . This should be ridge regularized. The equation is \n",
        "![](https://github.com/Eyu-148/CS254ML-HW/blob/main/images/G3.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQZ83iFiUJW6"
      },
      "source": [
        "def logRegressionGradientDescentR(x, y, thetaInit, eta, alpha, epochs):\n",
        "    # X : feature vector\n",
        "    # Y : target vector/ output vector\n",
        "    # theta : weight vector \n",
        "    # eta : learning rate\n",
        "    # alpha : regulirzation rate\n",
        "    # epochs : steps you want to take.\n",
        "    \n",
        "    m, d = x.shape\n",
        "    theta = thetaInit.copy()\n",
        "    \n",
        "    losses = [calcLogRegressionCostR(x, y, theta)]\n",
        "    for i in range(epochs):\n",
        "        \n",
        "        # Add code here (Gradient descent with regularization)\n",
        "        \n",
        "        theta -= eta * gradient\n",
        "        losses.append(calcLogRegressionCostR(x, y, theta))\n",
        "\n",
        "    return theta, losses   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5NdtSdbUJW6"
      },
      "source": [
        "# This part is given for the testing purpose    \n",
        "    \n",
        "initial_theta = np.zeros((x.shape[1], 1))\n",
        "eta = \n",
        "alpha = \n",
        "epochs =\n",
        "\n",
        "theta, cost = logRegressionGradientDescentR(x, y, initial_theta, eta, alpha, epochs)\n",
        "print(calcLogRegressionCostR(x, y, initial_theta, 0.1))\n",
        "print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P14fv_vUJW6"
      },
      "source": [
        "### Part 2, Q2 -  [20 pts]\n",
        "As you may have noticed in Part 2, Q1 plotting, the data are not linearly separable. When data are not linearly separable, one way to fit the data better is to create more features from each data point.Mapping data to polynomial terms is one of the simplest way.  \n",
        "\n",
        "1. [5 Points] Map the features into all polynomial terms of x1 and x2 up to the six power. Use PolynomialFeatures from scikit learn.\n",
        "\n",
        "![polyn6.png](attachment:polyn6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9AO9MvAUJW7"
      },
      "source": [
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOkAqjtgUJW7"
      },
      "source": [
        "2. [2 Points] Report optimal final θ on the polynominal features using logRegressionGradientDescent.\n",
        "\n",
        "Note: There should be 28 features as your are taking power of 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-JeblHFiUJW7"
      },
      "source": [
        "theta_scale = np.zeros((x_scale.shape[1],1))\n",
        "thetaOpt, cost = logRegressionGradientDescentR(x_scale, y, theta_scale, 0.01, 0, 250)\n",
        "print(thetaOpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LrF7OYmUJW7"
      },
      "source": [
        "3. [3 Points] Plot the cost with the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WvjdsJiUJW7"
      },
      "source": [
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxcU5DZSUJW7"
      },
      "source": [
        "4. [5 Points] Now, try to plot the decision boundary of the polynominal features.Use  logRegressionGradientDescentR for plotting the decision boundary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzy6QXIQUJW8"
      },
      "source": [
        "def plotBoundary(theta, x, y, poly, alpha=0):\n",
        "\n",
        "    # find optimal thetas\n",
        "    theta, cost = logRegressionGradientDescentR(x, y, theta, 0.2, alpha, 10_000)\n",
        "    \n",
        "    # create search space and placeholder\n",
        "    xvals = np.linspace(-1, 1.5, 50)\n",
        "    yvals = np.linspace(-1, 1.5, 50)\n",
        "    zvals = np.zeros((len(xvals), len(yvals)))\n",
        "    \n",
        "    # compute zval for all combinations of xvals/yvals\n",
        "    for i in range(len(xvals)):\n",
        "        for j in range(len(yvals)):\n",
        "            featuresij = poly.fit_transform(np.array([[xvals[i], yvals[j]]]))\n",
        "            zvals[j][i] = np.dot(theta.T, featuresij.T)\n",
        "    \n",
        "    \n",
        "    contour = plt.contour(xvals, yvals, zvals, [0])\n",
        "    plt.title(\"Decision Boundary with Alpha = \" + str(alpha))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qF8P2QvUJW8"
      },
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plotData()\n",
        "plotBoundary(theta_scale, x_scale, y, poly)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSPRp6EAUJW8"
      },
      "source": [
        "  5. [5 Points] What can you comment about the decision boundary from the previous question? Is the decision boundary behaving as expected?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS26M6W5UJW8"
      },
      "source": [
        "# Write your answer here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHAJvQO1UJW8"
      },
      "source": [
        "### Part 2, Q3 -  [15 pts]\n",
        "\n",
        "Regularization is an important part of fitting data more accurately. In the next part try four different regularization values and plot the decision boundary for each. The values might be a mixture of small, medium, and large values.\n",
        "\n",
        "Comment on the decision boundary for different regularization values? How is regularization effecting our model? Does this reduce overfitting?\n",
        "\n",
        "Note: Use regularized version of logRegressionGradientDescentR and calcLogRegressionCostR for decision boundary plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi1i3fv0UJW8"
      },
      "source": [
        "reg_vals = [ # add reg values ]\n",
        "plt.figure(figsize=(22,15))\n",
        "\n",
        "for i in range(len(reg_vals)):\n",
        "    plt.subplot(221 + i)\n",
        "    plotData()\n",
        "    plotBoundary(theta_scale, x_scale, y, poly, alpha=reg_vals[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEE5Uma3UJW8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}